### 分析 NMT 系统（25 分）

(a) (3 分) 查看 `src.vocab` 文件中的源语言词汇中的一些短语和单词示例。当将输入的中文序列编码为词汇中的“片段”时，标记器将序列映射到一系列词汇项，每个词汇项包含一个或多个字符（感谢 sentencepiece 标记器，即使原始文本没有空格，我们也可以执行这种分段）。考虑到这些信息，在嵌入层之后、将嵌入传递到双向编码器之前，添加一个一维卷积层如何有助于我们的 NMT 系统？提示：每个汉字要么是一个完整的单词，要么是一个词素。查找“电”、“脑”和“电脑”的含义作为示例。字符“电”（电）和“脑”（脑）组合成短语“电脑”表示计算机。

(b) (8 分) 这里我们展示了一些我们在 NMT 模型输出中发现的错误（这些错误与您刚训练的模型相同）。对于每个参考（即“金”）英文翻译和 NMT（即“模型”）英文翻译的示例，请：

1. 识别 NMT 翻译中的错误。
2. 提供模型可能出现错误的可能原因（可能是由于特定的语言结构或特定的模型限制）。
3. 描述一种我们可能修改 NMT 系统以修复所观察到的错误的方法。错误的修复方法不止一种。例如，可以调整隐藏层的大小或更改注意力机制。

下面是需要分析的翻译，如上所述只需分析每句中的下划线错误。请放心，您不需要懂中文就能回答这些问题。如果您需要了解源句子的更多信息，可以使用如 https://www.archchinese.com/chinese_english_dictionary.html 这样的资源来查找单词。您也可以搜索训练数据文件，以更好地了解某些字符出现的频率。

i. (2 分) 源句：贼人其后被警方拘捕及被判处盗窃罪名成立。  
参考翻译：the culprits were subsequently arrested and convicted.  
NMT 翻译：the culprit was subsequently arrested and sentenced to theft.

ii. (2 分) 源句：几乎已经没有地方容纳这些人, 资源已经用尽。  
参考翻译：there is almost no space to accommodate these people, and resources have run out.  
NMT 翻译：the resources have been exhausted and resources have been exhausted.

iii. (2 分) 源句：当局已经宣布今天是国殇日。  
参考翻译：authorities have announced a national mourning today.  
NMT 翻译：the administration has announced today’s day.

iv. (2 分) 源句：俗语有云:“唔做唔错”。  
参考翻译：“ act not, err not ”, so a saying goes.  
NMT 翻译：as the saying goes, “ it’s not wrong. ”

(c) (14 分) BLEU 分数是 NMT 系统中最常用的自动评估指标。通常是在整个测试集上计算，但这里我们将考虑定义为单个示例的 BLEU 分数。假设我们有一个源句子 \( s \)，一组 \( k \) 个参考翻译 \( r_1, \ldots, r_k \)，以及一个候选翻译 \( c \)。要计算 \( c \) 的 BLEU 分数，我们首先计算每个 \( n \) 的修改后的 \( n \) 元组精度 \( p_n \)，其中 \( n = 1, 2, 3, 4 \)：

\[ p_n = \frac{\sum_{\text{ngram} \in c} \min\left(\max_{i=1,\ldots,k} \text{Count}_{r_i}(\text{ngram}), \text{Count}_c(\text{ngram})\right)}{\sum_{\text{ngram} \in c} \text{Count}_c(\text{ngram})} \]

对于候选翻译 \( c \) 中出现的每个 \( n \) 元组，我们计算它在任何一个参考翻译中出现的最大次数，限制为它在 \( c \) 中出现的次数（这是分子）。我们将其除以 \( c \) 中的 \( n \) 元组数（分母）。

接下来，我们计算简短惩罚（BP）。令 \( \text{len}(c) \) 为 \( c \) 的长度，令 \( \text{len}(r) \) 为最接近 \( \text{len}(c) \) 的参考翻译长度（如果有两个同样接近的参考翻译长度，选择较短的 \( \text{len}(r) \)）。

\[ \text{BP} = \begin{cases} 
1 & \text{if } \text{len}(c) \geq \text{len}(r) \\
\exp\left(1 - \frac{\text{len}(r)}{\text{len}(c)}\right) & \text{otherwise}
\end{cases} \]

最后，候选 \( c \) 相对于 \( r_1, \ldots, r_k \) 的 BLEU 分数为：

\[ \text{BLEU} = \text{BP} \times \exp\left(\sum_{n=1}^4 \lambda_n \log p_n\right) \]

其中 \( \lambda_1, \lambda_2, \lambda_3, \lambda_4 \) 是加起来等于 1 的权重。这里的对数是自然对数。

i. (5 分) 请考虑这个示例：  
源句 \( s \)：需要有充足和可预测的资源。  
参考翻译 \( r_1 \)：resources have to be sufficient and they have to be predictable  
参考翻译 \( r_2 \)：adequate and predictable resources are required  
NMT 翻译 \( c_1 \)：there is a need for adequate and predictable resources  
NMT 翻译 \( c_2 \)：resources be sufficient and predictable to  
请计算 \( c_1 \) 和 \( c_2 \) 的 BLEU 分数。令 \( \lambda_i = 0.5 \) 对于 \( i \in \{1, 2\} \) 和 \( \lambda_i = 0 \) 对于 \( i \in \{3, 4\} \)（这意味着我们忽略 3-元组和 4-元组，即不计算 \( p_3 \) 或 \( p_4 \)）。  
计算 BLEU 分数时，展示你的计算过程（即展示你计算的 \( p_1 \)、\( p_2 \)、\( \text{len}(c) \)、\( \text{len}(r) \) 和 BP）。注意，BLEU 分数可以在 0 到 1 或 0 到 100 之间表达。此代码使用 0 到 100 的尺度，而在这个问题中我们使用 0 到 1 的尺度。请将你的答案保留三位小数。  
根据 BLEU 分数，哪一个 NMT 翻译被认为是更好的翻译？你同意这是更好的翻译吗？

ii. (5 分) 我们的硬盘损坏了，丢失了参考翻译 \( r_1 \)。请重新计算 \( c_1 \) 和 \( c_2 \) 的 BLEU 分数，这次仅相对于 \( r_2 \)。哪一个 NMT 翻译现在获得了更高的 BLEU 分数？你同意这是更好的翻译吗？

iii. (2 分) 由于数据可用性，NMT 系统通常只针对单个参考翻译进行评估。请解释为什么这可能会有问题。在你的解释中，讨论在有多个参考翻译与单个参考翻译时，BLEU 分数指标如何评估 NMT 翻译的质量。

iv. (2 分) 列出 BLEU 相对于人工评估作为机器翻译评估指标的两个优点和两个缺点。

(d) (4 分) 梯度搜索通常用于提高机器翻译系统的质量。在训练模型时，通过 `TensorBoard` 记录了同一示例句子在不同迭代中的梯度搜索结果，并在 TEXT 选项卡中可访问（图3）。记录的诊断信息包括以下字段：`example_source`（源句子标记）、`example_target`（真实目标句子标记）和 `hypotheses`（10 个假设，对应于梯度大小为 10 的搜索结果）。在神经机器翻译术语中，预测的翻译通常被称为假设。

i. (2 分) 在模型的训练迭代中，翻译质量是否有所提高？给出 200、3000 和最后一次迭代的三个翻译示例以说明你的答案。对于每次迭代，选择第一个梯度搜索假设作为示例。

ii. (2 分) 梯度搜索产生的各种假设在质量上如何比较？