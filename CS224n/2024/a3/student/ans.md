# part 1
## g

原因：通过这样的操作让填充的字符在计算注意力时权重无限降低，保证系统只注意真正的字符而不是填充的无意义的字符


## i


# part 2
## a

通过一维卷积，可以更好的利用和考虑上下文来形成对应的语义，例如例子中的电和脑通过一维卷积可以融合出电脑的语义


## b

A：错误在于没有采用复数形式和其对应的语法。原因：中文没有强制性的数量词限定，所以说语义会比较模糊。解决方式：

B：没有正确翻译后半段 原因：模型可能太小，无法翻译长的复杂的句子 解决方式：力大飞砖，加大模型参数量和训练资料量

C：没有正确翻译国殇日 原因：可能是国殇日一词在训练资料中出现次数太少，模型不能正确理解国殇的意思 解决方式：手动扩充该词相关语料或者采用稀疏矩阵优化法或者根据出现次数提升出现次数少的单词的梯度

D：没有正确反映出不做不错的意思 原因：可能是对于谚语等字数精简但是含义丰富的语句理解效果较差，也有可能是训练资料里面对于这种谚语翻译的情况较少，导致不能很好的学习如何翻译谚语 解决方式：扩充资料，加大参数量

## C

1：
2：
3：在单个参考翻译的情况下，BULE分数强迫模型尽量的让翻译和答案完全一模一样，在多个参考翻译中，BULE允许模型吸收不同翻译的结构和翻译情况，允许模型产生用词不同于单个句子但是最后得分仍然很高的句子
4：优点：节约成本，评价快捷；标准统一可以衡量
    缺点：抑制了模型产生意思一样但是构成句式不一样的句子的可能性；得分最高的句子不一定比得分低的句子好，尤其是有可能部分词会剧烈改变句意的情况下。
